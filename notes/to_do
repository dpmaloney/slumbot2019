New plan
  Resolve only rivers
  Build 200BB system
  Base systems should be 200BB with decent turn

Building on Amazon
  No local disk, right?
  How much storage do we need?
  If memory footprint is 768 GB, is the disk as well?
  
Write version of head_to_head which works with systems with different betting abstractions.
  Needs to take agents that can perform translation.
  Otherwise pretty similar to existing code.
  Is it going to be tricky handling that funny logic with bets smaller than the smallest bet
    size?
  Let's say system A bets 1/4 pot and we only have check or a 1/2 pot bet.
    With 44 maybe we want to check behind 50% or raise 50%.
    Could set reach probs accordingly.
    Tricky thing is that we want to force a raise when we map the 1/4 pot bet up to the 1/2 pot bet
    Can we have an array of booleans for force-raise?
  Could implement translate function
    But would need raise probs.

Can I evaluate resolving using head_to_head for the reentrant holdem system I built?
  Confirm results match those we get from play

What are the parameters for the base system I built on Amazon?
  b_params (null/null/wmls3.10k/wmls4.c.10k)
  big4sym
  tcfrqcss
  River sumprobs as ints are only 7.2 GB
Verify resolving working
  Evaluate with resolving against without resolving.
    Head-to-head?
    Approx RGBR?
      Verify working on small games.
      Should converge to full RGBR
      When working with resolving, should converge to full RGBR on solve_all_subgames

Verify backup resolving working

How to verify final system working?
  Evaluate head-to-head against Slumbot
    New system is only 100 BB.
    Build a new 200 BB system?!?  Could use reentrancy.
  run_approx_rgbr?

Verify head_to_head with resolving working.

Do I want to try to do turn resolving?
  Is it prohibitively slow?
    Measure speed on my desktop.  Later on Amazon.  I could buy a more powerful instance.
    I can also prohibit this system for API use.
  See if I build river resolving systems that are no more than 25% worse (by some measure)
    than turn resolving systems.

Build new system that only resolves rivers?  Redo experiments comparing turn-resolved
system to river-resolved system.  Depends on number of buckets, I suppose.  Can I do
a null turn abstraction in the base with reentrancy?  Around 70m buckets on the turn.
4 bytes: 2 bytes for the regret, 2 bytes for the sumprob.  Suppose 20 different initial
pot sizes, 25 different internal nodes, 2 players.  70m * 4 * 1000 = 280 GB.  Doable, no?

Write reassign program that reassigns probabilities of hands reaching rarely reached
states.  Rarely reached means of my entire distribution few if any hands reach that state.
Measure exploitability of reassigned system and also exploitability of reassigned+resolved.

Seems like our bet sizes are too small.
STATE:10:cr400c/r500f:KcAd|Jd5c/6s7c4h:400|-400:mb3b3aai|example

Implement resolving in agent

138 gigs for flop one char sumprobs files

Experiment with:
  Rounding near-zero probs to zero
  Eliminating rarely reached states
  Translation
  
Try solving a base game with no betting on the turn.
Should make run_rgbr read as it goes.
Is it a problem that our sumprobs files get gigantic?

Solve base game with reentrancy.
Can make the turn reentrant as well as the river.  Or even the flop.
Could try to merge adjacent pot sizes.
Can also change betting abstraction to limit number of distinct pot sizes.
One river state is 2.7b hands.  With 5 bytes per hand, that's 13.5 GB.  Can't have
  too many of those.  Can we get sumprobs down to as little as one byte?  Then it
  would be 5.4GB per state.  Still can't have too many.  An mb1b1 system will have
  four nonterminals on the river (root, c, b, cb).  With 20 different pot sizes,
  that's 80 states.  Times 5.4 GB, that's 432 GB.  Doable.
Have certain allowable pot-sizes/bet-tos.
Could go down to 100 BB to make my life easier.
But 200 BB doesn't actually add much.
11 pot sizes: 200BB, 100BB, 50BB, 40BB, 30BB, 20BB, 10BB, 8BB, 6BB, 4BB, 2BB.
With 2.7b river hands and 44 states, you will only see a river hand in a state
on 1/100b iterations.  Will we need a huge number of iterations to converge?
Results look promising, but I haven't tried an equivalently sized system with
a regular (non-reentrant tree).  bigh5 system is 35 megs.  Maybe try nnnwml1
or some other "nnn" system.

I would like a fast approximate real-game best-response strategy that will handle
resolved systems.  Has to allow deviation from the base strategy starting at the
root.  We could allow just one bet size for the responder.  Evaluate only one
hand for best responder?  Does that help?

Can I evaluate on holdem/mb1b1 systems?  I think best-response takes 6 hours (?)
locally.  Could be faster on Amazon.  How much memory would we need?
Four pot sizes at river initial nodes, 4 nodes, 2 succs.  So 32 * 2.7b * 4
(for int sumprobs) =~ 350 GB.  Doable.

Implement an ACPC bot with backup resolving and translation.
Should I copy my server code into this repo?
Should I shrink the size of the strategy even further?  Yes, eventually.

Big system on Amazon.  144g for one system, 279g for two.

run_approx_rgbr multithreading is not very good.  If we are sampling only a single flop,
for example, we will have single-threaded processing.  In fact, don't even get to
multi-threading part when sampling a flop board.

Can I precompute all flops?  Probably not.  Could only solve an mb1b1 system.  What
would we do when opponent deviates?  Can't dynamically solve a flop.
Can I precompute all flop subgames for certain common preflop betting sequences like
b2c and b4c?  1755 flop boards.

If exploitability is getting worse already, should I stop training?

Experiment with game that we can compute exact exploitability of.
Solve with tcfr and null abstraction for preflop/flop and coarse abstraction for turn/river
What does the exploitability look like when we resolve turns?
See if it helps to train the base for a long time or not.
May need to use a bigger game than holdem5.

Does high exploitability result from best-responder playing to poorly trained nodes?

What is the exploitability introduced by translation?

Can we learn range-vs-range estimates and introduce into training?  Learn a base system
with learned estimates at some street (river?).  This is kind of what Deep Stack does.
Need to incorporate into CFR+.  Will need to implement a regression model in C++.
Probably not deep neural networks.  Could do a nearest neighbor thing.  Blend CVs of
N nearest neighbors.

What if we started with an abstraction with only all-in bets; train that to convergence;
then add in the next largest bet sizes; train that to convergence; etc.

Could solve base system with only check/call on the river and very fine-grained card
abstraction.  Seems like that might distort the strategy.  No good reason to bet big
with strong hands or strong draws on the flop?  But at least we shouldn't have
exploitable holes.

Investigate some questions on holdem5/null/mb1b1:
1) Is targeted CFR better or external CFR?
2) Is FTL better or regret matching?
3) Is my new bcfr2 implementation much slower than my old tcfr implementation?

Try backup approach in which we always solve a subtree rooted at a street-initial node.
Possibly even a turn subgame even when we have reached the river.

Measure speed of solving backup turn subtrees.

Assess progress of CFR on base system with head_to_head.  Quantize probs.
Maybe I should just use a large instance and load all the sumprobs into memory.
Or I could do head-to-head with resolving?  I could quantize the probs on disk first.
River sumprobs for one system:   14.4 GB
Turn sumprobs for one system:    8.4 GB
Flop sumprobs for one system:    514.4 GB
Preflop sumprobs for one system: 2.2 MB
I guess I had 768 GB of RAM for CFR.
I can reduce by a factor of 4 pretty easily.
Wait, can I just use my built-in quantizing?
Need 540GB + 135GB = 700 GB?

Train and assess big sym system.
1) Seems like exploitability gets substantially worse over time.  Confirm.
2) Seems like head to head improves and is asymptoting.
3) Would like to know if exploitability decreases when incorporating resolving.
4) Can I look at flop ranges and see if they look wacky?

Progressive resolving.    How can I test if progressive endgame solving is working well?  Evaluate
head to head a system with more bets against a system with fewer bets.  Incorporate progressive
resolving for the system with fewer bets.  What do I expect to see?  Competitive results?
Should be better than translation.  Can do this with unabstracted game.

Redo combined results in debugging that may be stale due to bug fix.

We saw some bad results solving street-internal nodes with the unsafe method.  I don't think
this is a bug; I just think resolving at street-internal nodes with the unsafe method is inherently
unreliable.  In the particular case I looked into, the unsafe method yielded poor results because
it failed to take into account that the opponent could change his preflop behavior.  In
particular, he exploited by betting weak hands preflop and again betting the weak hands
postflop and ended up getting too many folds.  The unsafe method assumed that 32o never reached
the node in question because the ranges are locked in, and as a consequence learned to call
more tightly.

Resolving at street-initial nodes will always be better because the chance event (the board
card or cards) introduces randomness into the distributions and ensures that each player has a
mixture of strong and weak hands.

Some options:
1) Use CFR-D or combined subgame solving;
2) Back up and solve the entire street subgame.

Combined method may need some work to account for the fact that the path from the root to
the current resolve node may pass through parts of the tree previously resolved.  The dynamic
CBR calculation may need to look at both base probs and resolve probs.

For CFR-D, why don't we have the opponent best-respond?  What about at the special node -
can he best respond there, or should he mix?

New endgame solving approach: try to force the opponent to prefer the same actions as he did
in the base.  A weaker version of CFR-D.  How would we force this?  Would want this to be a
defeasible constraint.

With lazy initialization we are no longer doing pruning after each opp action in OppChoice().
Does that hurt performance?  We could initialize there.  Does that defeat the point of lazy
initialization?  Maybe not.

Do SetStreetBuckets() lazily.

The hand tree should be linked to the regrets/sumprobs.  root_bd and root_st must be the same.

Is turn resolving too slow?  I saw 12.26 seconds single-threaded for cccc with the big3sym
betting abstraction (one bet and raise postflop).  Down to 3.6 seconds with the new multithreading
code and 8 threads.  I guess that's OK although I think klondikefx reports 2 seconds.  May not
be good enough with multiple concurrent users.

Should lbd and gbd have different types so that we cannot mistakenly pass one to the other?

Do I want to presolve commonly reached turn subgames?  There are 63,000 turn boards, keep in mind.
With 3 second per board, that's 189,000 seconds.  That's over 50 hours.  And that's just one
betting state.  Maybe not.

Allow HandValueTree to be created from multiple threads at once.  There's a way to do this
in C++.  Google "singleton".

Better approx RGBR calculation?

Use ReachProbs in VCFR?  Limit to opponent.

Multithread head_to_head.  

Can we get rid of two nodes in VCFR?

Templating stuff is a mess.
Ugliness in vcfr.cpp, cfr_utils.cpp.
Dynamic casting.
Don't want switch in inner loop (if ints, then this; if doubles, then this).
Need fast implementation of RMProbs(), UpdateRegrets(), ProcessOppProbs().
Maybe VCFR can just have i_regrets and d_regrets, and i_sumprobs and d_sumprobs, and use
  the appropriate one.
We need a switch, but we can do it outside of the inner loop.
May need multiple implementations of OurChoice(), OppChoice().
To keep number of implementations down, require regrets and sumprobs to either both be
  doubles or both be ints.  Need to support chars?
What if regrets and sumprobs are chars?  Cast to ints or doubles as needed.
May need two implementations of OurChoice(), two of OppChoice().

Build a new heads-up system:
1) Will use base for preflop and flop; resolve turn and river
2) Therefore null abstraction preflop and flop
3) Therefore rich betting abstraction preflop and flop w/ one bet and raise turn and river
4) Asymmetric betting abstraction with few bet sizes for us?  Seems like one is too few.
5) Boosting?  Doesn't help by current measures.
6) Reentrant on turn and river?  Doesn't gain much.
7) Quantize on turn and river, at least.
8) Don't save sumprobs for turn or river

Can I run RGBR on holdem/mb1b1 game?  I think it tries to create a HandTree for the entire
game.  Won't fit in memory?  Could instead create hand tree for each max street subgame.
Would that add to the computational cost?

Can I get rid of busy loops and usleep() in new multithreading code.

Investigate board on ms3f1t1r1h5/nxhs3 which leads to such high exploitability.  Any lessons
about card abstraction?

Rename run_tcfr to run_mccfr, change Algorithm setting from tcfr to mccfr.  Rename vcfr
to reflect that CFR+ is the main algorithm.

Evaluate char quantization for flop, turn and river.

Get rid of old and new CFR directories.

Evaluate boosting on game with many betting sequences (mb2b2aai).  Right now seeing no head
to head advantage.  How can I test if there is an exploitability advantage?  Need approx
RGBR program?

Do I want to just use symmetric training so that I don't need to worry about what bet sizes
are most important?

Write show_joint_reach_probs program which shows joint reach probs of every terminal node.
Should be able to reuse code from head_to_head.  Allow sampling of river boards.

Write approx RGBR program.  Support more than two streets.  street_ may not be last street.
Support subgame solving.

Incorporate combined endgame solving into head_to_head; see how well it works.

Experiment with combination of:
1) TCFR
2) holdem
3) kmeans abstraction; null for preflop/flop, 1000 buckets for turn/river
4) Quantize turn and river
5) Asymmetric betting abstraction (asymc)
6) Should I turn off saving of sumprobs for turn/river?  Try that later.

Try CFR+ with a hard warmup.

Can we resolve flops offline like Lars?  Solving flop subgame (mb1b1) taking 7m10s.
6 resolves is 44m, but we will want to use a richer preflop abstraction than mb1b1.
Call it 1 hour.  1755 flops is 1755 thread-hours.  With 8 threads, 220 hours.  About 9
days.  Doable.  On Amazon would be faster.  But if we want a richer preflop or flop betting
abstraction, that's going to make a big difference.

Could make head_to_head twice as fast with unsafe endgame solving.  Solving each subgame twice
now and we don't need to.

head_to_head may repeatedly solve flop or turn subgames.  Should figure out the minimal set
we need to resolve.  Also: if we're going to solve a flop subgame, should we just go ahead
and evaluate every river board consistent with that flop?

Measure speed of turn resolving.  One bet size and one raise size for turn and river.
Add multithreading?  VCFR already supports spinning off threads.  Need to allow control of
what street to split on.

Switch to mb2b2ai as testbed.  More actions may mean:
* TCFR outperforms ECFR
* Boosting helps resolving (not seeing that yet)
* Combined resolving may outperform unsafe resolving

Create resolve params, use for things like head_to_head and solve_all_subgames.  Should help
reduce length of command lines.

Experiment with MCTS as a tool for approximate best-response calculations.

Support progressive endgame resolving.  Including resolves rooted at street initial nodes.

Experiment with multiplayer and reentrancy.  Evaluate with head-to-head?  Can we use h5;
i.e., a 20 card deck?  6 hole cards, 5 board cards, 9 unused cards.  I guess so.

Support multiplayer in endgame solving.  Need to support multiplayer betting trees in
CreateSubtree() in solve_all_subgames.

Build a h5ms3f1p6 system with a non-reentrant tree.  Currently using hs3 buckets, but should
probably do something better for the river, and bucket the turn as well.

Finish converting unsigned ints to ints everywhere.

Get rid of cast to float of cbr values in dynamic_cbr.cpp.

Should I boost CVs instead of boosting regrets?  Can I boost only at leaf nodes?  I don't want
to boost at several nonterminals on the way to a river terminal node, do I?  Wouldn't that lead
to too much boosting?

Boosting at terminal nodes is possibly excessive.  I only want to force players to reach every
nonterminal.  But maybe it wouldn't hurt too much to do so.

For deeply embedded nodes, I am worried about the boosting becoming very attenuated.  Only
1/1000 hands may go down the preflop succ.  Then maybe only 1/1000 down a flop succ.  By the
logic of Targeted CFR, can we do iterations that are forced to go down the boosted succs?

Use newer FileReader and FileWriter classes in slumbot2019

Can we clean up templated code.  Or abandon that approach even?  OppChoice() is a bit of a
mess.  Try to clean that up if nothing else.  Would it help to make VCFR templated?

Incorporate more modern C++:
1) Replace new with unique_ptr everywhere possible
2) Look into std::array and other container we might want to use
3) Use auto wherever possible; e.g., for iterators
4) Use modern C++ multithreading capabilities
5) Use modern C++ mutex capabilities
6) Isn't there a new kind of iteration?
7) Use modern C++ braced initialization
8) Get rid of typedefs.  Used aliases.
9) Use scoped enums.
10) CFRValues should not take pointer to betting tree
11) Replace NULL with nullptr everywhere possible

Fix determ play

It's a mess that we need to pass around root_bd_st/root_bd and if we get it wrong there are subtle
errors.

Is there a discrepancy with suited vs. unsuited hands in TCFR?  Can get very different strategies.

Multithread play and/or play_resolved

Can we get rid of two ways of hole card pair indexing?

Understand why we lost so badly to ackr.  Preflop purification?
